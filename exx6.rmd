---
title: "Упражнение № 6"
author: "Блинов И И"
date: "07 04 2021"
output: html_document
---

## Вариант № 4

1. Примените указанные в варианте метод к набору данных по своему варианту (см. таблицу ниже). Не забудьте предварительно сделать из категориальных переменных факторы. Выберите оптимальную модель с помощью кросс-валидации. Выведите её коэффициенты с помощью функции coef(). Рассчитайте MSE модели на тестовой выборке.

2. Примените указанные в варианте метод к набору данных по своему варианту (см. таблицу ниже). Для модели:
- Подогнать модель на всей выборке и вычислить ошибку (MSE) с кросс-валидацией. По наименьшей MSE подобрать оптимальное значение настроечного параметра метода (гиперпараметр λ или число главных компонент M). - Подогнать модель с оптимальным значением параметра на обучающей выборке, посчитать MSE на тестовой.
- Подогнать модель с оптимальным значением параметра на всех данных, вывести характеристики модели функцией summary().

3. Сравните оптимальные модели, полученные в заданиях 1 и 2 по MSE на тестовой выборке. Какой метод дал лучший результат? Доля тестовой выборки: 50%.


## Регуляризация линейных моделей

Модели: линейная регрессия, ридж, лассо, PCR, PLS.

Данные: *AUTO {ISLR}*


```{r setup, include=FALSE}
library('ISLR')              # набор данных Auto
library('leaps')             # функция regsubset() -- отбор оптимального 
                             #  подмножества переменных
library('glmnet')            # функция glmnet() -- лассо
library('pls')               # регрессия на главные компоненты -- pcr()
library('knitr')
                             #  и частный МНК -- plsr()
knitr::opts_chunk$set(echo = TRUE)
```


Набор данных по автомобилям *Auto*.


```{r}
my.seed <- 4
#?Auto
Auto <- subset(Auto, select = c(mpg, cylinders, displacement, horsepower, weight, acceleration, year, origin))
Auto$cylinders <- as.factor(Auto$cylinders)
Auto$origin <- as.factor(Auto$origin)
```


```{r}
names(Auto)
```


```{r}
dim(Auto)
str(Auto)
```

Считаем число пропусков в зависимой переменной и убираем их.

```{r}
# считаем пропуски
sum(is.na(Auto$mpg))
```






## Задание 1 

# Отбор оптимального подмножества


Подгоняем модели с сочетаниями предикторов до 11 (максимум в данных)

```{r}
regfit.full <- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)

regfit.full <- regsubsets(mpg ~ ., Auto, nvmax = 11)
reg.summary <- summary(regfit.full)
reg.summary
# структура отчёта по модели (ищем характеристики качества)
names(reg.summary)
# R^2 и скорректированный R^2
round(reg.summary$rsq, 3)
```




```{r}
# на графике
plot(1:11, reg.summary$rsq, type = 'b',
     xlab = 'Количество предикторов', ylab = 'R-квадрат')
# сода же добавим скорректированный R-квадрат
points(1:11, reg.summary$adjr2, col = 'red')
# модель с максимальным скорректированным R-квадратом
which.max(reg.summary$adjr2)
points(which.max(reg.summary$adjr2), 
       reg.summary$adjr2[which.max(reg.summary$adjr2)],
       col = 'red', cex = 2, pch = 20)
legend('bottomright', legend = c('R^2', 'R^2_adg'),
      col = c('black', 'red'), lty = c(1, NA),
      pch = c(1, 1))
# C_p
reg.summary$cp

```

```{r}
# C_p
reg.summary$cp
# число предикторов у оптимального значения критерия
which.min(reg.summary$cp)
```

```{r}
# график
plot(reg.summary$cp, xlab = 'Число предикторов',
     ylab = 'C_p', type = 'b')
points(which.min(reg.summary$cp),
       reg.summary$cp[which.min(reg.summary$cp)], 
       col = 'red', cex = 2, pch = 20)
```
```{r}
# BIC
reg.summary$bic
# число предикторов у оптимального значения критерия
which.min(reg.summary$bic)
### 7
# график
plot(reg.summary$bic, xlab = 'Число предикторов',
     ylab = 'BIC', type = 'b')
points(which.min(reg.summary$bic),
       reg.summary$bic[which.min(reg.summary$bic)], 
       col = 'red', cex = 2, pch = 20)
```


```{r}
# метод plot для визуализации результатов
?plot.regsubsets
plot(regfit.full, scale = 'r2')
plot(regfit.full, scale = 'adjr2')
plot(regfit.full, scale = 'Cp')
plot(regfit.full, scale = 'bic')
round(coef(regfit.full, 7), 3)
```


k-кратная кросс-валидация


```{r}
# функция для прогноза для функции regsubset()
predict.regsubsets <- function(object, newdata, id, ...){
    form <- as.formula(object$call[[2]])
    mat <- model.matrix(form, newdata)
    coefi <- coef(object, id = id)
    xvars <- names(coefi)
    mat[, xvars] %*% coefi
}
# отбираем 10 блоков наблюдений
k <- 10
set.seed(my.seed)
folds <- sample(1:k, nrow(Auto), replace = T)
# заготовка под матрицу с ошибками
cv.errors <- matrix(NA, k, 11, dimnames = list(NULL, paste(1:11)))
# заполняем матрицу в цикле по блокам данных
for (j in 1:k){
    best.fit <- regsubsets(mpg ~ ., data = Auto[folds != j, ],
                           nvmax = 11)
    # теперь цикл по количеству объясняющих переменных
    for (i in 1:11){
        # модельные значения mpg
        pred <- predict(best.fit,Auto[folds == j, ], id = i)
        # вписываем ошибку в матрицу
        cv.errors[j, i] <- mean((Auto$mpg[folds == j] - pred)^2)
    }
}
# усредняем матрицу по каждому столбцу (т.е. по блокам наблюдений), 
#  чтобы получить оценку MSE для каждой модели с фиксированным 
#  количеством объясняющих переменных
mean.cv.errors <- apply(cv.errors, 2, mean)
round(mean.cv.errors, 0)
```

```{r}
# на графике
plot(mean.cv.errors, type = 'b')
points(which.min(mean.cv.errors), mean.cv.errors[which.min(mean.cv.errors)],
       col = 'red', pch = 20, cex = 2)
```

```{r}
reg.best <- regsubsets(mpg ~ ., data = Auto, nvmax = 10)
round(coef(reg.best, 10), 3)
```

Расчет MSE по тестовой выборке

```{r}
DF.auto <- Auto
# общее число наблюдений
n <- nrow(DF.auto)
# доля обучающей выборки
train.percent <- 0.5
# выбрать наблюдения в обучающую выборку
set.seed(my.seed)
inTrain <- sample(1:n, n * train.percent)
# фактические значения Y на тестовой выборке
y.test.fact <- DF.auto$mpg[-inTrain]
# присоединить таблицу с данными: названия стоблцов будут доступны напрямую
attach(DF.auto)
# подгонка модели на обучающей выборке
fit.lm <- lm(mpg ~ . , subset = inTrain,  data = Auto)
# подгонка линейной модели на обучающей выборке
fit.lm <- lm(mpg ~ . , 
               subset = inTrain,  data = Auto)
#объединение уровней переменной cylinders
fit.lm$xlevels[['cylinders']] <- union(fit.lm$xlevels[['cylinders']], levels(DF.auto$cylinders))
# прогноз на тестовую
y.test.lm <- predict(fit.lm, DF.auto[-inTrain, ])
# считаем MSE на тестовой выборке
MSE.lm <- mean((y.test.fact - y.test.lm)^2)
# отсоединить таблицу с данными
detach(DF.auto)
# смотрим ошибку
MSE.lm
```




## Зачада 2 

#Регрессия на главные компоненты

```{r}
# из-за синтаксиса glmnet() формируем явно матрицу объясняющих...
# из-за синтаксиса glmnet() формируем явно матрицу объясняющих...
x <- model.matrix(mpg ~ ., Auto)[, -1]
# и вектор значений зависимой переменной
y <- Auto$mpg
y.test <- y[-inTrain]
set.seed(2)
pcr.fit <- pcr(mpg ~ ., data = Auto, scale = T, validation = 'CV')
summary(pcr.fit)
# график ошибок
validationplot(pcr.fit, val.type = 'MSEP')
```

##Подбор оптиального M: кросс-валидация на обучающей выборке

```{r}
set.seed(my.seed)
pcr.fit <- pcr(mpg ~ ., subset = inTrain, data = Auto, validation = 'CV')
validationplot(pcr.fit, val.type = 'MSEP')
```
```{r}
# MSE на тестовой выборке
pcr.pred <- predict(pcr.fit, x[-inTrain, ], ncomp = 7)
round(mean((pcr.pred - y.test)^2), 0)
```


```{r}
# подгоняем модель на всей выборке для M = 7 
#  (оптимально по методу перекрёстной проверки)
pcr.fit <- pcr(y ~ x, scale = T, ncomp = 7)
summary(pcr.fit)
```


```{r}
# MSE на тестовой выборке с 10 объясняющими переменными (отбор оптимального подмножества)
opt.test <- predict(best.fit, Auto[-inTrain, ], id = 7)
opt.mse.test <- round(mean((opt.test - y.test)^2), 2)
# MSE на тестовой выборке (регрессия на главные компоненты)
regres.test <- predict(pcr.fit, x[-inTrain, ], ncomp = 7)
regres.mse.test <- round(mean((pcr.pred - y.test)^2), 2)
MSE.test <- rbind(opt.mse.test, regres.mse.test)
row.names(MSE.test) <- c('MSE (отбор оптимального подмножества)', 'MSE (регрессия на главные компоненты)')
kable(MSE.test)
```

Сравнивая результаты расчётов MSE на тестовой выборке для двух оптимальных моделей, полученных в заданиях 1 и 2, можно заключить, что стандартная ошибка MSE модели №1 (отбор оптимального подмножества) оказалась меньше, чем MSE модели №2. Таким образом, модель №1 (отбор путём пошагового исключения) оказалась лучшей.
